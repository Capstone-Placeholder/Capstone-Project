{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Functions\n",
    "Functions to create:\n",
    "- splitting into train, validate, test\n",
    "- scale train, validate, test\n",
    "- create clusters with kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artists</th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>external_ids</th>\n",
       "      <th>external_urls</th>\n",
       "      <th>href</th>\n",
       "      <th>id</th>\n",
       "      <th>is_local</th>\n",
       "      <th>is_playable</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>preview_url</th>\n",
       "      <th>track_number</th>\n",
       "      <th>type</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'album_type': 'album', 'artists': [{'external...</td>\n",
       "      <td>[{'external_urls': {'spotify': 'https://open.s...</td>\n",
       "      <td>1</td>\n",
       "      <td>482830</td>\n",
       "      <td>False</td>\n",
       "      <td>{'isrc': 'USAT21300959'}</td>\n",
       "      <td>{'spotify': 'https://open.spotify.com/track/5C...</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/5CQ30WqJwcep...</td>\n",
       "      <td>5CQ30WqJwcep0pYcV4AMNc</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Stairway to Heaven - Remaster</td>\n",
       "      <td>78</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/8226164717312bc4...</td>\n",
       "      <td>4</td>\n",
       "      <td>track</td>\n",
       "      <td>spotify:track:5CQ30WqJwcep0pYcV4AMNc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               album  \\\n",
       "0  {'album_type': 'album', 'artists': [{'external...   \n",
       "\n",
       "                                             artists  disc_number  \\\n",
       "0  [{'external_urls': {'spotify': 'https://open.s...            1   \n",
       "\n",
       "   duration_ms  explicit              external_ids  \\\n",
       "0       482830     False  {'isrc': 'USAT21300959'}   \n",
       "\n",
       "                                       external_urls  \\\n",
       "0  {'spotify': 'https://open.spotify.com/track/5C...   \n",
       "\n",
       "                                                href                      id  \\\n",
       "0  https://api.spotify.com/v1/tracks/5CQ30WqJwcep...  5CQ30WqJwcep0pYcV4AMNc   \n",
       "\n",
       "   is_local  is_playable                           name  popularity  \\\n",
       "0     False         True  Stairway to Heaven - Remaster          78   \n",
       "\n",
       "                                         preview_url  track_number   type  \\\n",
       "0  https://p.scdn.co/mp3-preview/8226164717312bc4...             4  track   \n",
       "\n",
       "                                    uri  \n",
       "0  spotify:track:5CQ30WqJwcep0pYcV4AMNc  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DF\n",
    "- using sklearn split functions to split df into 705 train, 20% validate, 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split data into train, validate, and test\n",
    "def split_df(df):\n",
    "\n",
    "    '''\n",
    "    Splits dataframe into train, validate, and test - 70%, 20%, 10% respectively.\n",
    "    Prints out the percentage shape and row/column shape of the split dataframes.\n",
    "    Returns train, validate, test.\n",
    "    '''\n",
    "\n",
    "    # Import to use split function, can only split two at a time\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # First, split into train + validate together and test by itself\n",
    "    # Test will be %10 of the data, train + validate is %70 for now\n",
    "    # Set random_state so we can reproduce the same 'random' data\n",
    "    train_validate, test = train_test_split(df, test_size = .10, random_state = 666)\n",
    "\n",
    "    # Second, split train + validate into their seperate dataframes\n",
    "    # Train will be %70 of the data, Validate will be %20 of the data\n",
    "    # Set random_state so we can reproduce the same 'random' data\n",
    "    train, validate = train_test_split(train_validate, test_size = .22, random_state = 666)\n",
    "\n",
    "    # These two print functions allow us to ensure the date is properly split\n",
    "    # Will print the shape of each variable when running the function\n",
    "    print(\"train shape: \", train.shape, \", validate shape: \", validate.shape, \", test shape: \", test.shape)\n",
    "\n",
    "    # Will print the shape of each variable as a percentage of the total data set\n",
    "    # Variable to hold the sum of all rows (total observations in the data)\n",
    "    total = df.count()[0]\n",
    "    \n",
    "    #calculating percentages of the split df to the original df\n",
    "    train_percent = round(((train.shape[0])/total),2) * 100\n",
    "    validate_percent = round(((validate.shape[0])/total),2) * 100\n",
    "    test_percent = round(((test.shape[0])/total),2) * 100\n",
    "    \n",
    "    print(\"\\ntrain percent: \", train_percent, \", validate percent: \", validate_percent, \n",
    "            \", test percent: \", test_percent)\n",
    "\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (7, 17) , validate shape:  (2, 17) , test shape:  (1, 17)\n",
      "\n",
      "train percent:  70.0 , validate percent:  20.0 , test percent:  10.0\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = split_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Data\n",
    "- MinMaxScaler\n",
    "    - a linear scaling method that transforms our features such that the range is between 0 and 1\n",
    "    \n",
    "- Standard\n",
    "    - standardization is a linear transformation of our data such that is looks like the standard normal distribution\n",
    "    - it will have a mean of 0 and a standard deviation of 1\n",
    "    - scales and then centers\n",
    "    \n",
    "- RobustScaler\n",
    "    - another linear transformation more robust to outliers\n",
    "    \n",
    "### Function to scale:\n",
    "- takes train, validate, and test and returns the three scaled versions\n",
    "- parameter for predict drops the specified predictive variable in the df, in this case popularity\n",
    "- parameter for scaler specifies to use MinMax, Standard, or Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, validate, test, predict, scaler):\n",
    "\n",
    "    '''\n",
    "    Scales a df based on scaler chosen: 'MinMax', 'Standard', or 'Robust'. \n",
    "    Needs three dfs, train, validate, and test. Fits the scaler object to train \n",
    "    only, transforms on all 3. Returns the three dfs scaled.\n",
    "    '''\n",
    "    \n",
    "    import sklearn.preprocessing\n",
    "    \n",
    "    # removing predictive feature\n",
    "    X_train = train.drop(predict, axis=1)\n",
    "    X_validate = validate.drop(predict, axis=1)\n",
    "    X_test = test.drop(predict, axis=1)\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "\n",
    "        # create scaler object for MinMax Scaler\n",
    "        scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "        \n",
    "    elif scaler == 'Standard':\n",
    "        \n",
    "        # create scaler object for Standard Scaler\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        \n",
    "    elif scaler == 'Robust':\n",
    "        \n",
    "        # create scaler object for Robust Scaler\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        \n",
    "    # Note that we only call .fit with the training data,\n",
    "    # but we use .transform to apply the scaling to all the data splits.\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # transforming all three dfs with the scaler object\n",
    "    # this turns it into an array\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_validate_scaled = scaler.transform(X_validate)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # converting scaled array back to df\n",
    "    # first by converting to a df, it will not have the original index and column names\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "        \n",
    "    # setting index to original dfs\n",
    "    X_train_scaled.index = X_train.index\n",
    "    X_validate_scaled.index = X_validate.index\n",
    "    X_test_scaled.index = X_test.index\n",
    "        \n",
    "    # renaming columns to original dfs\n",
    "    X_train_scaled.columns = X_train.columns\n",
    "    X_validate_scaled.columns = X_validate.columns\n",
    "    X_test_scaled.columns = X_test.columns\n",
    "\n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disc_number', 'duration_ms', 'popularity', 'track_number']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe().columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing scaling on numeric columns\n",
    "columns = train.describe().columns.to_list()\n",
    "train = train[columns]\n",
    "validate = validate[columns]\n",
    "test = test[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_validate_scaled, X_test_scaled = scale_data(train, validate, test, 'popularity','MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_number</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>track_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059469</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347861</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195823</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609115</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disc_number  duration_ms  track_number\n",
       "2          0.0     0.000000      0.000000\n",
       "6          0.0     0.059469      0.000000\n",
       "4          0.0     0.347861      1.000000\n",
       "0          0.0     1.000000      0.500000\n",
       "1          0.0     0.557499      0.000000\n",
       "8          0.0     0.195823      1.000000\n",
       "9          0.0     0.609115      0.833333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
